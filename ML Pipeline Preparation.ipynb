{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ML Pipeline Preparation\n",
    "I will build an effective machine learning pipeline that help me classifies the disaster messages\n",
    "### 1. Import libraries and load data from database.\n",
    "- Importing Python libraries\n",
    "- Loading dataset from database with [`read_sql_table`](https://pandas.pydata.org/pandas-docs/stable/generated/pandas.read_sql_table.html)\n",
    "- Defining feature and target variables X and Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-22T04:50:07.615563Z",
     "start_time": "2019-10-22T04:50:07.600621Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\DELL\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     C:\\Users\\DELL\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\DELL\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\DELL\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "# import libraries\n",
    "import nltk\n",
    "nltk.download(['punkt', 'averaged_perceptron_tagger', 'wordnet', 'stopwords'])\n",
    "import json\n",
    "import joblib\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import string\n",
    "import re\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.corpus import stopwords\n",
    "from sklearn.metrics import confusion_matrix, make_scorer\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfTransformer,TfidfVectorizer\n",
    "from sklearn.pipeline import Pipeline, FeatureUnion\n",
    "from sqlalchemy import create_engine\n",
    "from sklearn.ensemble import BaggingClassifier, RandomForestClassifier, AdaBoostClassifier\n",
    "from sklearn.multioutput import MultiOutputClassifier\n",
    "\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-22T04:43:52.170978Z",
     "start_time": "2019-10-22T04:43:52.104058Z"
    }
   },
   "outputs": [],
   "source": [
    "# load data from database\n",
    "def load_data(database = '../data/disaster-response-messages.db', sqltable= 'messages'):\n",
    "    engine = create_engine('sqlite:///'+database)\n",
    "    df = pd.read_sql_table(sqltable, con = engine)\n",
    "    X = df['message']\n",
    "    Y = df.iloc[:, 4:]\n",
    "    return X,Y\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-22T04:43:54.969786Z",
     "start_time": "2019-10-22T04:43:53.386628Z"
    }
   },
   "outputs": [],
   "source": [
    "X, y = load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-22T04:50:24.082083Z",
     "start_time": "2019-10-22T04:50:24.036208Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>related</th>\n",
       "      <th>request</th>\n",
       "      <th>offer</th>\n",
       "      <th>aid_related</th>\n",
       "      <th>medical_help</th>\n",
       "      <th>medical_products</th>\n",
       "      <th>search_and_rescue</th>\n",
       "      <th>security</th>\n",
       "      <th>military</th>\n",
       "      <th>child_alone</th>\n",
       "      <th>...</th>\n",
       "      <th>aid_centers</th>\n",
       "      <th>other_infrastructure</th>\n",
       "      <th>weather_related</th>\n",
       "      <th>floods</th>\n",
       "      <th>storm</th>\n",
       "      <th>fire</th>\n",
       "      <th>earthquake</th>\n",
       "      <th>cold</th>\n",
       "      <th>other_weather</th>\n",
       "      <th>direct_report</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>26211</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>26212</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>26213</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>26214</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>26215</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>26216 rows × 36 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       related  request  offer  aid_related  medical_help  medical_products  \\\n",
       "0            1        0      0            0             0                 0   \n",
       "1            1        0      0            1             0                 0   \n",
       "2            1        0      0            0             0                 0   \n",
       "3            1        1      0            1             0                 1   \n",
       "4            1        0      0            0             0                 0   \n",
       "...        ...      ...    ...          ...           ...               ...   \n",
       "26211        0        0      0            0             0                 0   \n",
       "26212        0        0      0            0             0                 0   \n",
       "26213        1        0      0            0             0                 0   \n",
       "26214        1        0      0            1             0                 0   \n",
       "26215        1        0      0            0             0                 0   \n",
       "\n",
       "       search_and_rescue  security  military  child_alone  ...  aid_centers  \\\n",
       "0                      0         0         0            0  ...            0   \n",
       "1                      0         0         0            0  ...            0   \n",
       "2                      0         0         0            0  ...            0   \n",
       "3                      0         0         0            0  ...            0   \n",
       "4                      0         0         0            0  ...            0   \n",
       "...                  ...       ...       ...          ...  ...          ...   \n",
       "26211                  0         0         0            0  ...            0   \n",
       "26212                  0         0         0            0  ...            0   \n",
       "26213                  0         0         0            0  ...            0   \n",
       "26214                  0         0         1            0  ...            0   \n",
       "26215                  0         0         0            0  ...            0   \n",
       "\n",
       "       other_infrastructure  weather_related  floods  storm  fire  earthquake  \\\n",
       "0                         0                0       0      0     0           0   \n",
       "1                         0                1       0      1     0           0   \n",
       "2                         0                0       0      0     0           0   \n",
       "3                         0                0       0      0     0           0   \n",
       "4                         0                0       0      0     0           0   \n",
       "...                     ...              ...     ...    ...   ...         ...   \n",
       "26211                     0                0       0      0     0           0   \n",
       "26212                     0                0       0      0     0           0   \n",
       "26213                     0                0       0      0     0           0   \n",
       "26214                     0                0       0      0     0           0   \n",
       "26215                     0                0       0      0     0           0   \n",
       "\n",
       "       cold  other_weather  direct_report  \n",
       "0         0              0              0  \n",
       "1         0              0              0  \n",
       "2         0              0              0  \n",
       "3         0              0              0  \n",
       "4         0              0              0  \n",
       "...     ...            ...            ...  \n",
       "26211     0              0              0  \n",
       "26212     0              0              0  \n",
       "26213     0              0              0  \n",
       "26214     0              0              0  \n",
       "26215     0              0              0  \n",
       "\n",
       "[26216 rows x 36 columns]"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Writing a tokenization function to process my text data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-22T04:50:26.488899Z",
     "start_time": "2019-10-22T04:50:26.469946Z"
    }
   },
   "outputs": [],
   "source": [
    "#define the regular expression for the URL\n",
    "url_regex = 'http[s]?://(?:[a-zA-Z]|[0-9]|[$-_@.&+]|[!*\\(\\),]|(?:%[0-9a-fA-F][0-9a-fA-F]))+'\n",
    "punctuations_list = string.punctuation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-22T04:50:33.671767Z",
     "start_time": "2019-10-22T04:50:33.646831Z"
    }
   },
   "outputs": [],
   "source": [
    "def tokenize(text):\n",
    "            \"\"\"\n",
    "            Tokenize function\n",
    "            \n",
    "            Arguments:\n",
    "                text -> list of text messages (Arabic)\n",
    "            Output:\n",
    "                clean_tokens -> tokenized text, clean for ML modeling\n",
    "            \"\"\"\n",
    "            \n",
    "            #replacing any url with \"urlplaceholder\" string\n",
    "            detected_urls = re.findall(url_regex, text)\n",
    "            for url in detected_urls:\n",
    "                text = text.replace(url, \"urlplaceholder\")\n",
    "                \n",
    "            #normalize text\n",
    "            text = text.lower()\n",
    "            \n",
    "            #tokenizing the text message\n",
    "            tokens = word_tokenize(text)\n",
    "            \n",
    "            #defining the lemmatization object \n",
    "            lemmatizer = WordNetLemmatizer()\n",
    "            \n",
    "            #defining a translator object to remove all punctations\n",
    "            table = str.maketrans('', '', punctuations_list)\n",
    "\n",
    "            clean_tokens = []\n",
    "            #cleaning every token by stemming and removing punctations and appending to the clean list\n",
    "            for tok in tokens:\n",
    "                clean_tok = lemmatizer.lemmatize(tok)     \n",
    "                clean_tok = clean_tok.translate(table)        \n",
    "                clean_tokens.append(clean_tok)\n",
    "            \n",
    "            #removing the stopwords from the clean_tokens list\n",
    "            clean_tokens = [w for w in clean_tokens if w != '' and w not in stopwords.words('english')]\n",
    "\n",
    "\n",
    "            return clean_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-22T04:50:35.411530Z",
     "start_time": "2019-10-22T04:50:35.370651Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Weather update - a cold front from Cuba that could pass over Haiti\n",
      "['weather', 'update', 'cold', 'front', 'cuba', 'could', 'pas', 'haiti']\n",
      "Is the Hurricane over or is it not over\n",
      "['hurricane']\n",
      "Looking for someone but no name\n",
      "['looking', 'someone', 'name']\n",
      "UN reports Leogane 80-90 destroyed. Only Hospital St. Croix functioning. Needs supplies desperately.\n",
      "['un', 'report', 'leogane', '8090', 'destroyed', 'hospital', 'st', 'croix', 'functioning', 'need', 'supply', 'desperately']\n",
      "says: west side of Haiti, rest of the country today and tonight\n",
      "['say', 'west', 'side', 'haiti', 'rest', 'country', 'today', 'tonight']\n"
     ]
    }
   ],
   "source": [
    "#test tokenize function on the first five messages\n",
    "for x in X[:5]:\n",
    "    print(x)\n",
    "    print(tokenize(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Building a machine learning pipeline\n",
    "This machine pipeline should take in the `message` column as input and output classification results on the other 36 categories in the dataset. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-22T05:05:11.007689Z",
     "start_time": "2019-10-22T05:05:11.003701Z"
    }
   },
   "outputs": [],
   "source": [
    "pipeline = Pipeline([\n",
    "    ('tfidfvect',TfidfVectorizer(tokenizer=tokenize)),\n",
    "    ('clf', MultiOutputClassifier(AdaBoostClassifier()))\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Training pipeline\n",
    "- Spliting data into train and test sets\n",
    "- Training pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-22T05:05:12.500039Z",
     "start_time": "2019-10-22T05:05:12.472127Z"
    }
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-22T05:12:49.620414Z",
     "start_time": "2019-10-22T05:05:13.045064Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(memory=None,\n",
       "         steps=[('tfidfvect',\n",
       "                 TfidfVectorizer(analyzer='word', binary=False,\n",
       "                                 decode_error='strict',\n",
       "                                 dtype=<class 'numpy.float64'>,\n",
       "                                 encoding='utf-8', input='content',\n",
       "                                 lowercase=True, max_df=1.0, max_features=None,\n",
       "                                 min_df=1, ngram_range=(1, 1), norm='l2',\n",
       "                                 preprocessor=None, smooth_idf=True,\n",
       "                                 stop_words=None, strip_accents=None,\n",
       "                                 sublinear_tf=False,\n",
       "                                 token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
       "                                 tokenizer=<function tokenize at 0x00000265D0C4C950>,\n",
       "                                 use_idf=True, vocabulary=None)),\n",
       "                ('clf',\n",
       "                 MultiOutputClassifier(estimator=AdaBoostClassifier(algorithm='SAMME.R',\n",
       "                                                                    base_estimator=None,\n",
       "                                                                    learning_rate=1.0,\n",
       "                                                                    n_estimators=50,\n",
       "                                                                    random_state=None),\n",
       "                                       n_jobs=None))],\n",
       "         verbose=False)"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipeline.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Testing my model\n",
    "Reporting the f1 score, precision and recall for each output category of the dataset. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-22T05:22:54.563958Z",
     "start_time": "2019-10-22T05:20:52.912578Z"
    }
   },
   "outputs": [],
   "source": [
    "Y_pred = pipeline.predict(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-22T05:23:11.904576Z",
     "start_time": "2019-10-22T05:23:11.049054Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "related\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.67      0.12      0.20      1563\n",
      "           1       0.77      0.98      0.87      4944\n",
      "           2       0.46      0.13      0.20        47\n",
      "\n",
      "    accuracy                           0.77      6554\n",
      "   macro avg       0.64      0.41      0.42      6554\n",
      "weighted avg       0.75      0.77      0.70      6554\n",
      "\n",
      "request\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.97      0.94      5443\n",
      "           1       0.77      0.50      0.61      1111\n",
      "\n",
      "    accuracy                           0.89      6554\n",
      "   macro avg       0.84      0.73      0.77      6554\n",
      "weighted avg       0.88      0.89      0.88      6554\n",
      "\n",
      "offer\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      1.00      1.00      6521\n",
      "           1       0.00      0.00      0.00        33\n",
      "\n",
      "    accuracy                           0.99      6554\n",
      "   macro avg       0.50      0.50      0.50      6554\n",
      "weighted avg       0.99      0.99      0.99      6554\n",
      "\n",
      "aid_related\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.76      0.86      0.81      3884\n",
      "           1       0.74      0.61      0.67      2670\n",
      "\n",
      "    accuracy                           0.76      6554\n",
      "   macro avg       0.75      0.73      0.74      6554\n",
      "weighted avg       0.75      0.76      0.75      6554\n",
      "\n",
      "medical_help\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.98      0.96      6019\n",
      "           1       0.56      0.25      0.34       535\n",
      "\n",
      "    accuracy                           0.92      6554\n",
      "   macro avg       0.75      0.61      0.65      6554\n",
      "weighted avg       0.91      0.92      0.91      6554\n",
      "\n",
      "medical_products\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.99      0.98      6210\n",
      "           1       0.67      0.32      0.43       344\n",
      "\n",
      "    accuracy                           0.96      6554\n",
      "   macro avg       0.82      0.65      0.70      6554\n",
      "weighted avg       0.95      0.96      0.95      6554\n",
      "\n",
      "search_and_rescue\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      1.00      0.99      6395\n",
      "           1       0.56      0.15      0.24       159\n",
      "\n",
      "    accuracy                           0.98      6554\n",
      "   macro avg       0.77      0.57      0.61      6554\n",
      "weighted avg       0.97      0.98      0.97      6554\n",
      "\n",
      "security\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      1.00      0.99      6438\n",
      "           1       0.17      0.03      0.06       116\n",
      "\n",
      "    accuracy                           0.98      6554\n",
      "   macro avg       0.57      0.52      0.52      6554\n",
      "weighted avg       0.97      0.98      0.97      6554\n",
      "\n",
      "military\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.99      0.99      6354\n",
      "           1       0.55      0.32      0.40       200\n",
      "\n",
      "    accuracy                           0.97      6554\n",
      "   macro avg       0.76      0.65      0.69      6554\n",
      "weighted avg       0.97      0.97      0.97      6554\n",
      "\n",
      "child_alone\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00      6554\n",
      "\n",
      "    accuracy                           1.00      6554\n",
      "   macro avg       1.00      1.00      1.00      6554\n",
      "weighted avg       1.00      1.00      1.00      6554\n",
      "\n",
      "water\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.99      0.98      6136\n",
      "           1       0.75      0.65      0.69       418\n",
      "\n",
      "    accuracy                           0.96      6554\n",
      "   macro avg       0.86      0.82      0.84      6554\n",
      "weighted avg       0.96      0.96      0.96      6554\n",
      "\n",
      "food\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.98      0.97      5809\n",
      "           1       0.81      0.70      0.75       745\n",
      "\n",
      "    accuracy                           0.95      6554\n",
      "   macro avg       0.89      0.84      0.86      6554\n",
      "weighted avg       0.95      0.95      0.95      6554\n",
      "\n",
      "shelter\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.98      0.97      5973\n",
      "           1       0.77      0.58      0.66       581\n",
      "\n",
      "    accuracy                           0.95      6554\n",
      "   macro avg       0.87      0.78      0.82      6554\n",
      "weighted avg       0.94      0.95      0.94      6554\n",
      "\n",
      "clothing\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      1.00      0.99      6456\n",
      "           1       0.57      0.31      0.40        98\n",
      "\n",
      "    accuracy                           0.99      6554\n",
      "   macro avg       0.78      0.65      0.70      6554\n",
      "weighted avg       0.98      0.99      0.98      6554\n",
      "\n",
      "money\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.99      0.99      6421\n",
      "           1       0.42      0.25      0.31       133\n",
      "\n",
      "    accuracy                           0.98      6554\n",
      "   macro avg       0.70      0.62      0.65      6554\n",
      "weighted avg       0.97      0.98      0.97      6554\n",
      "\n",
      "missing_people\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      1.00      0.99      6481\n",
      "           1       0.68      0.18      0.28        73\n",
      "\n",
      "    accuracy                           0.99      6554\n",
      "   macro avg       0.84      0.59      0.64      6554\n",
      "weighted avg       0.99      0.99      0.99      6554\n",
      "\n",
      "refugees\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.99      0.98      6339\n",
      "           1       0.54      0.28      0.37       215\n",
      "\n",
      "    accuracy                           0.97      6554\n",
      "   macro avg       0.76      0.64      0.68      6554\n",
      "weighted avg       0.96      0.97      0.96      6554\n",
      "\n",
      "death\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.99      0.98      6257\n",
      "           1       0.74      0.42      0.53       297\n",
      "\n",
      "    accuracy                           0.97      6554\n",
      "   macro avg       0.86      0.71      0.76      6554\n",
      "weighted avg       0.96      0.97      0.96      6554\n",
      "\n",
      "other_aid\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.98      0.93      5690\n",
      "           1       0.50      0.14      0.22       864\n",
      "\n",
      "    accuracy                           0.87      6554\n",
      "   macro avg       0.69      0.56      0.57      6554\n",
      "weighted avg       0.83      0.87      0.83      6554\n",
      "\n",
      "infrastructure_related\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.99      0.97      6143\n",
      "           1       0.40      0.09      0.15       411\n",
      "\n",
      "    accuracy                           0.93      6554\n",
      "   macro avg       0.67      0.54      0.56      6554\n",
      "weighted avg       0.91      0.93      0.91      6554\n",
      "\n",
      "transport\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      1.00      0.98      6251\n",
      "           1       0.72      0.20      0.31       303\n",
      "\n",
      "    accuracy                           0.96      6554\n",
      "   macro avg       0.84      0.60      0.65      6554\n",
      "weighted avg       0.95      0.96      0.95      6554\n",
      "\n",
      "buildings\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.99      0.98      6231\n",
      "           1       0.71      0.37      0.49       323\n",
      "\n",
      "    accuracy                           0.96      6554\n",
      "   macro avg       0.84      0.68      0.73      6554\n",
      "weighted avg       0.96      0.96      0.96      6554\n",
      "\n",
      "electricity\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      1.00      0.99      6407\n",
      "           1       0.61      0.21      0.31       147\n",
      "\n",
      "    accuracy                           0.98      6554\n",
      "   macro avg       0.80      0.60      0.65      6554\n",
      "weighted avg       0.97      0.98      0.97      6554\n",
      "\n",
      "tools\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      1.00      1.00      6511\n",
      "           1       0.00      0.00      0.00        43\n",
      "\n",
      "    accuracy                           0.99      6554\n",
      "   macro avg       0.50      0.50      0.50      6554\n",
      "weighted avg       0.99      0.99      0.99      6554\n",
      "\n",
      "hospitals\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      1.00      0.99      6498\n",
      "           1       0.31      0.14      0.20        56\n",
      "\n",
      "    accuracy                           0.99      6554\n",
      "   macro avg       0.65      0.57      0.60      6554\n",
      "weighted avg       0.99      0.99      0.99      6554\n",
      "\n",
      "shops\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00      6530\n",
      "           1       0.00      0.00      0.00        24\n",
      "\n",
      "    accuracy                           1.00      6554\n",
      "   macro avg       0.50      0.50      0.50      6554\n",
      "weighted avg       0.99      1.00      0.99      6554\n",
      "\n",
      "aid_centers\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      1.00      0.99      6473\n",
      "           1       0.22      0.06      0.10        81\n",
      "\n",
      "    accuracy                           0.99      6554\n",
      "   macro avg       0.60      0.53      0.54      6554\n",
      "weighted avg       0.98      0.99      0.98      6554\n",
      "\n",
      "other_infrastructure\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.99      0.98      6271\n",
      "           1       0.35      0.08      0.13       283\n",
      "\n",
      "    accuracy                           0.95      6554\n",
      "   macro avg       0.66      0.54      0.55      6554\n",
      "weighted avg       0.93      0.95      0.94      6554\n",
      "\n",
      "weather_related\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.96      0.92      4781\n",
      "           1       0.85      0.66      0.74      1773\n",
      "\n",
      "    accuracy                           0.88      6554\n",
      "   macro avg       0.87      0.81      0.83      6554\n",
      "weighted avg       0.87      0.88      0.87      6554\n",
      "\n",
      "floods\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.99      0.98      6035\n",
      "           1       0.81      0.58      0.68       519\n",
      "\n",
      "    "
     ]
    },
    {
     "data": {
      "text/html": [
       "<b>limit_output extension: Maximum message size of 10000 exceeded with 10837 characters</b>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "for i,col in enumerate(y_test.columns):\n",
    "    print(col+'\\n' ,classification_report(y_test.loc[:,col], Y_pred[:,i]))\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6. Improving your model\n",
    "Use grid search to find better parameters. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-22T05:24:00.189873Z",
     "start_time": "2019-10-22T05:24:00.181544Z"
    }
   },
   "outputs": [],
   "source": [
    "parameters = {\n",
    "        'tfidfvect__ngram_range': ((1, 1), (1, 2)),\n",
    "        'tfidfvect__max_df': (0.5, 1.0),\n",
    "        'tfidfvect__max_features': (None, 5000),\n",
    "        'clf__estimator__n_estimators': [50, 100] \n",
    "}\n",
    "\n",
    "cv = GridSearchCV(pipeline, param_grid=parameters)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-22T09:58:34.369796Z",
     "start_time": "2019-10-22T05:24:01.061308Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv='warn', error_score='raise-deprecating',\n",
       "             estimator=Pipeline(memory=None,\n",
       "                                steps=[('tfidfvect',\n",
       "                                        TfidfVectorizer(analyzer='word',\n",
       "                                                        binary=False,\n",
       "                                                        decode_error='strict',\n",
       "                                                        dtype=<class 'numpy.float64'>,\n",
       "                                                        encoding='utf-8',\n",
       "                                                        input='content',\n",
       "                                                        lowercase=True,\n",
       "                                                        max_df=1.0,\n",
       "                                                        max_features=None,\n",
       "                                                        min_df=1,\n",
       "                                                        ngram_range=(1, 1),\n",
       "                                                        norm='l2',\n",
       "                                                        preprocessor=None,\n",
       "                                                        smooth_idf=True,...\n",
       "                                                                                           base_estimator=None,\n",
       "                                                                                           learning_rate=1.0,\n",
       "                                                                                           n_estimators=50,\n",
       "                                                                                           random_state=None),\n",
       "                                                              n_jobs=None))],\n",
       "                                verbose=False),\n",
       "             iid='warn', n_jobs=None,\n",
       "             param_grid={'clf__estimator__n_estimators': [50, 100],\n",
       "                         'tfidfvect__max_df': (0.5, 1.0),\n",
       "                         'tfidfvect__max_features': (None, 5000),\n",
       "                         'tfidfvect__ngram_range': ((1, 1), (1, 2))},\n",
       "             pre_dispatch='2*n_jobs', refit=True, return_train_score=False,\n",
       "             scoring=None, verbose=0)"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7. Testing my best model\n",
    "Showing the accuracy, precision, and recall of the tuned model.  \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-22T11:20:26.013084Z",
     "start_time": "2019-10-22T11:18:44.321288Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "related\n",
      " accuracy: 0.7718950259383582\tprecision: 0.7718950259383582\trecall: 0.7718950259383582 \n",
      "\n",
      "request\n",
      " accuracy: 0.8947207812023192\tprecision: 0.8947207812023192\trecall: 0.8947207812023192 \n",
      "\n",
      "offer\n",
      " accuracy: 0.9945071711931645\tprecision: 0.9945071711931645\trecall: 0.9945071711931645 \n",
      "\n",
      "aid_related\n",
      " accuracy: 0.7691486115349405\tprecision: 0.7691486115349405\trecall: 0.7691486115349405 \n",
      "\n",
      "medical_help\n",
      " accuracy: 0.9252364967958498\tprecision: 0.9252364967958498\trecall: 0.9252364967958498 \n",
      "\n",
      "medical_products\n",
      " accuracy: 0.954226426609704\tprecision: 0.954226426609704\trecall: 0.954226426609704 \n",
      "\n",
      "search_and_rescue\n",
      " accuracy: 0.9752822703692402\tprecision: 0.9752822703692402\trecall: 0.9752822703692402 \n",
      "\n",
      "security\n",
      " accuracy: 0.9800122062862374\tprecision: 0.9800122062862374\trecall: 0.9800122062862374 \n",
      "\n",
      "military\n",
      " accuracy: 0.9711626487641135\tprecision: 0.9711626487641135\trecall: 0.9711626487641135 \n",
      "\n",
      "child_alone\n",
      " accuracy: 1.0\tprecision: 1.0\trecall: 1.0 \n",
      "\n",
      "water\n",
      " accuracy: 0.9642966127555691\tprecision: 0.9642966127555691\trecall: 0.9642966127555691 \n",
      "\n",
      "food\n",
      " accuracy: 0.9433933475740006\tprecision: 0.9433933475740006\trecall: 0.9433933475740006 \n",
      "\n",
      "shelter\n",
      " accuracy: 0.9444613976197742\tprecision: 0.9444613976197742\trecall: 0.9444613976197742 \n",
      "\n",
      "clothing\n",
      " accuracy: 0.9870308208727495\tprecision: 0.9870308208727495\trecall: 0.9870308208727495 \n",
      "\n",
      "money\n",
      " accuracy: 0.9777235276167227\tprecision: 0.9777235276167227\trecall: 0.9777235276167227 \n",
      "\n",
      "missing_people\n",
      " accuracy: 0.9896246566981995\tprecision: 0.9896246566981995\trecall: 0.9896246566981995 \n",
      "\n",
      "refugees\n",
      " accuracy: 0.9668904485810192\tprecision: 0.9668904485810192\trecall: 0.9668904485810192 \n",
      "\n",
      "death\n",
      " accuracy: 0.9671956057369545\tprecision: 0.9671956057369545\trecall: 0.9671956057369545 \n",
      "\n",
      "other_aid\n",
      " accuracy: 0.8671040585901739\tprecision: 0.8671040585901739\trecall: 0.8671040585901739 \n",
      "\n",
      "infrastructure_related\n",
      " accuracy: 0.9342386328959414\tprecision: 0.9342386328959414\trecall: 0.9342386328959414 \n",
      "\n",
      "transport\n",
      " accuracy: 0.958651205370766\tprecision: 0.958651205370766\trecall: 0.958651205370766 \n",
      "\n",
      "buildings\n",
      " accuracy: 0.9594140982606042\tprecision: 0.9594140982606042\trecall: 0.9594140982606042 \n",
      "\n",
      "electricity\n",
      " accuracy: 0.9783338419285932\tprecision: 0.9783338419285932\trecall: 0.9783338419285932 \n",
      "\n",
      "tools\n",
      " accuracy: 0.992065913945682\tprecision: 0.992065913945682\trecall: 0.992065913945682 \n",
      "\n",
      "hospitals\n",
      " accuracy: 0.9897772352761672\tprecision: 0.9897772352761672\trecall: 0.9897772352761672 \n",
      "\n",
      "shops\n",
      " accuracy: 0.9957277998169057\tprecision: 0.9957277998169057\trecall: 0.9957277998169057 \n",
      "\n",
      "aid_centers\n",
      " accuracy: 0.9851998779371376\tprecision: 0.9851998779371376\trecall: 0.9851998779371376 \n",
      "\n",
      "other_infrastructure\n",
      " accuracy: 0.950259383582545\tprecision: 0.950259383582545\trecall: 0.950259383582545 \n",
      "\n",
      "weather_related\n",
      " accuracy: 0.8770216661580714\tprecision: 0.8770216661580714\trecall: 0.8770216661580714 \n",
      "\n",
      "floods\n",
      " accuracy: 0.9563625267012511\tprecision: 0.9563625267012511\trecall: 0.9563625267012511 \n",
      "\n",
      "storm\n",
      " accuracy: 0.9375953616112298\tprecision: 0.9375953616112298\trecall: 0.9375953616112298 \n",
      "\n",
      "fire\n",
      " accuracy: 0.9896246566981995\tprecision: 0.9896246566981995\trecall: 0.9896246566981995 \n",
      "\n",
      "earthquake\n",
      " accuracy: 0.9684162343606958\tprecision: 0.9684162343606958\trecall: 0.9684162343606958 \n",
      "\n",
      "cold\n",
      " accuracy: 0.9812328349099786\tprecision: 0.9812328349099786\trecall: 0.9812328349099786 \n",
      "\n",
      "other_weather\n",
      " accuracy: 0.9455294476655478\tprecision: 0.9455294476655478\trecall: 0.9455294476655478 \n",
      "\n",
      "direct_report\n",
      " accuracy: 0.8463533719865731\tprecision: 0.8463533719865731\trecall: 0.8463533719865731 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "Y_pred = cv.predict(X_test)\n",
    "\n",
    "#Test the model using accuracy, precision, recall\n",
    "for i,col in enumerate(y_test.columns):\n",
    "    accuracy = accuracy_score(y_test.iloc[:,i], Y_pred[:,i])\n",
    "    precision = precision_score(y_test.iloc[:,i], Y_pred[:,i], average='micro')\n",
    "    recall = recall_score(y_test.iloc[:,i], Y_pred[:,i], average='micro')\n",
    "    print(col+'\\n' , \"accuracy: {}\\tprecision: {}\\trecall: {} \\n\".format(accuracy, precision, recall))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8. Try improving my model further:\n",
    "* trying other machine learning algorithms (RandomForest Classifier)\n",
    "* adding other feature besides the TF-IDF (message length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-22T11:22:42.399636Z",
     "start_time": "2019-10-22T11:22:42.337231Z"
    }
   },
   "outputs": [],
   "source": [
    "class MessageLength(BaseEstimator, TransformerMixin):\n",
    "    \"\"\"\n",
    "     Message Length Extractor class\n",
    "    \n",
    "    This class extract the message length ,\n",
    "    creating a new feature for the ML classifier\n",
    "    \"\"\"\n",
    "\n",
    "    def computing_message_length(self, text):\n",
    "        return len(text)\n",
    "\n",
    "    def fit(self, x, y=None):\n",
    "        return self\n",
    "\n",
    "    def transform(self, X):\n",
    "        X_tagged = pd.Series(X).apply(self.computing_message_length)\n",
    "        return pd.DataFrame(X_tagged)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-20T05:16:03.259867Z",
     "start_time": "2019-10-20T05:16:03.214990Z"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-22T11:23:17.720230Z",
     "start_time": "2019-10-22T11:23:17.651965Z"
    }
   },
   "outputs": [],
   "source": [
    "pipeline = Pipeline([\n",
    "        ('features', FeatureUnion([\n",
    "            ('tfidfvect',TfidfVectorizer(tokenizer=tokenize)),\n",
    "            ('computing_message_length',MessageLength())       \n",
    "            \n",
    "        ])),\n",
    "\n",
    "        ('clf', MultiOutputClassifier(RandomForestClassifier()))\n",
    "    ])\n",
    "    \n",
    "parameters = {\n",
    "        'features__tfidfvect__ngram_range': ((1, 1), (1, 2)),\n",
    "        'features__tfidfvect__max_df': (0.75, 1.0),\n",
    "        'features__tfidfvect__max_features': (None, 5000),\n",
    "        'clf__estimator__n_estimators': [50, 100] ,\n",
    "        'features__transformer_weights': (\n",
    "            {'tfidfvect': 1,  'computing_message_length' : 0.5}, \n",
    "            {'tfidfvect': 0.5,   'computing_message_length' : 1})\n",
    "             \n",
    "        \n",
    "    \n",
    "    }\n",
    "\n",
    "cv1 = GridSearchCV(pipeline, param_grid=parameters)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2019-10-22T11:23:22.869Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\DELL\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_split.py:1978: FutureWarning: The default value of cv will change from 3 to 5 in version 0.22. Specify it explicitly to silence this warning.\n",
      "  warnings.warn(CV_WARNING, FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "cv1.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_pred = cv.predict(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i,col in enumerate(y_test.columns):\n",
    "    \n",
    "    labels = np.unique(y_pred)\n",
    "    confusion_mat = confusion_matrix(Y_test.iloc[:,i], y_pred[:,i], labels=labels)\n",
    "    accuracy = (y_pred[:,i] == Y_test.iloc[:,i]).mean()\n",
    "    class_report = classification_report(Y_test.iloc[:,i], y_pred[:,i])\n",
    "    f1_sc = f1_score(Y_test.iloc[:,i], y_pred[:,i])\n",
    "    prec = precision_score(Y_test.iloc[:,i], y_pred[:,i])\n",
    "\n",
    "    print(\"Labels:\", labels)\n",
    "    print(\"Confusion Matrix:\\n\", confusion_mat)\n",
    "    print(\"Accuracy: \", accuracy)\n",
    "    print(\"precision: \", prec)\n",
    "    print(\"f1_score: \", f1_sc)\n",
    "    print(\"\\nClassification report:\\n \", class_report ) \n",
    "\n",
    "print(\"\\nBest Parameters: \", cv.best_params_)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 9. Export your model as a pickle file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-22T11:22:16.008556Z",
     "start_time": "2019-10-22T11:22:04.434906Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['./models/clf.pkl']"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "joblib.dump(cv, './models/clf.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
